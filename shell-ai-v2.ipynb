{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":880348,"sourceType":"datasetVersion","datasetId":469408},{"sourceId":6189596,"sourceType":"datasetVersion","datasetId":3552708},{"sourceId":6261649,"sourceType":"datasetVersion","datasetId":3598948}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-12T07:00:20.140646Z","iopub.execute_input":"2024-10-12T07:00:20.141042Z","iopub.status.idle":"2024-10-12T07:00:20.196426Z","shell.execute_reply.started":"2024-10-12T07:00:20.141006Z","shell.execute_reply":"2024-10-12T07:00:20.195166Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/biomass/Biomass_History.csv\n/kaggle/input/distance/Distance_Matrix.csv\n/kaggle/input/biomass-data/biomass.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install keras-rl2\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:00:30.341317Z","iopub.execute_input":"2024-10-12T07:00:30.341820Z","iopub.status.idle":"2024-10-12T07:00:46.300995Z","shell.execute_reply.started":"2024-10-12T07:00:30.341783Z","shell.execute_reply":"2024-10-12T07:00:46.299652Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting keras-rl2\n  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from keras-rl2) (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.51.3)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.9.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.4.13)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (4.6.3)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras-rl2) (0.2.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras-rl2) (1.11.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.3.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->keras-rl2) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.2.2)\nInstalling collected packages: keras-rl2\nSuccessfully installed keras-rl2-1.0.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import plotly.express as px\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import MeanSquaredLogarithmicError,MeanSquaredError,MeanAbsoluteError\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point, MultiPoint\nimport rtree\nfrom sklearn.neighbors import NearestNeighbors\nfrom gym import Env\nfrom gym.spaces import Box, MultiDiscrete, Dict,Discrete\nfrom shapely.ops import nearest_points\nimport geopandas as gpd\nimport seaborn as sns\nimport random\nfrom rl.agents import DQNAgent\nfrom rl.policy import BoltzmannQPolicy\nfrom rl.memory import SequentialMemory\nimport bisect\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:01:11.993046Z","iopub.execute_input":"2024-10-12T07:01:11.993508Z","iopub.status.idle":"2024-10-12T07:01:24.916672Z","shell.execute_reply.started":"2024-10-12T07:01:11.993469Z","shell.execute_reply":"2024-10-12T07:01:24.915644Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"biomass = pd.read_csv(\"/kaggle/input/biomass/Biomass_History.csv\")\ndistance = pd.read_csv(\"/kaggle/input/distance/Distance_Matrix.csv\")\n# creating point objects, will be useful later on \npoints = []\nfor i, row in biomass.iterrows():\n    points.append((float(row['Longitude']),float(row[\"Latitude\"])) )\n\nbiomass[\"Geometries\"] = points\nbiomass[\"Type\"] = \"Biomass prod.plants\"\nprint(biomass.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:01:29.809051Z","iopub.execute_input":"2024-10-12T07:01:29.809804Z","iopub.status.idle":"2024-10-12T07:01:32.267297Z","shell.execute_reply.started":"2024-10-12T07:01:29.809768Z","shell.execute_reply":"2024-10-12T07:01:32.266039Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   Index  Latitude  Longitude       2010       2011       2012       2013  \\\n0      0  24.66818   71.33144   8.475744   8.868568   9.202181   6.023070   \n1      1  24.66818   71.41106  24.029778  28.551348  25.866415  21.634459   \n2      2  24.66818   71.49069  44.831635  66.111168  56.982258  53.003735   \n3      3  24.66818   71.57031  59.974419  80.821304  78.956543  63.160561   \n4      4  24.66818   71.64994  14.653370  19.327524  21.928144  17.899586   \n\n        2014       2015       2016        2017            Geometries  \\\n0  10.788374   6.647325   7.387925    5.180296  (71.33144, 24.66818)   \n1  34.419411  27.361908  40.431847   42.126945  (71.41106, 24.66818)   \n2  70.917908  42.517117  59.181629   73.203232  (71.49069, 24.66818)   \n3  93.513924  70.203171  74.536720  101.067352  (71.57031, 24.66818)   \n4  19.534035  19.165791  16.531315   26.086885  (71.64994, 24.66818)   \n\n                  Type  \n0  Biomass prod.plants  \n1  Biomass prod.plants  \n2  Biomass prod.plants  \n3  Biomass prod.plants  \n4  Biomass prod.plants  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"sns.heatmap(biomass.corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:35:36.596927Z","iopub.execute_input":"2024-10-06T23:35:36.597348Z","iopub.status.idle":"2024-10-06T23:35:37.265090Z","shell.execute_reply.started":"2024-10-06T23:35:36.597316Z","shell.execute_reply":"2024-10-06T23:35:37.264047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter_mapbox(biomass, lat=\"Latitude\", lon=\"Longitude\",hover_data=[\"Index\"],\n                        color=\"2014\", zoom=3, height=400)\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show(renderer='iframe')","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:35:41.299280Z","iopub.execute_input":"2024-10-06T23:35:41.300066Z","iopub.status.idle":"2024-10-06T23:35:42.762175Z","shell.execute_reply.started":"2024-10-06T23:35:41.300030Z","shell.execute_reply":"2024-10-06T23:35:42.761068Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predictions using neural networks\n\n\"\"\" First a little data prep. We need to batch the results from 2010 till 2016, the 2017 \nresults will serve as the target values for the neural network\"\"\"\n\nx = biomass[[str(i+2000) for i in range(10,17)]].values\nprint(x.shape)\ny = biomass[\"2017\"].values\nprint(y.shape)\nscaler = StandardScaler()\nx = scaler.fit_transform(x)\nX_train,X_test,Y_train,Y_test = train_test_split(x,y, test_size = 0.25, random_state = 32)\nprint (X_train.shape, X_test.shape)\n\n\ndef build_net_no_dropout(input_size):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(input_size,activation = 'relu'))\n    model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(32, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(1, activation = 'relu'))\n    return model\n\n\ndef build_net_with_dropout(input_size):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(input_size,activation = 'relu',kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(128, activation = \"relu\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.7))\n    model.add(tf.keras.layers.Dense(32, activation = \"relu\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dense(1, activation = 'relu'))\n    return model\n\ndef model_run(model,train_x,val_y, train_y, val_x, num_epochs):\n    loss = MeanSquaredLogarithmicError()\n    optimizer = \"adam\"\n    model.compile( loss= loss, optimizer = optimizer, metrics = [\"msle\"])\n    #training\n    history = model.fit(train_x,train_y, epochs = num_epochs,batch_size= 70, verbose = 1,validation_data = (val_x,val_y))\n    return history\n\ndef plotter(history,metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric])\n    plt.xlabel('Epochs')\n    plt.ylabel(metric)\n    plt.legend([metric,'val_'+metric])\n    plt.show()\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:14:04.563474Z","iopub.execute_input":"2024-10-09T12:14:04.563997Z","iopub.status.idle":"2024-10-09T12:14:04.627275Z","shell.execute_reply.started":"2024-10-09T12:14:04.563953Z","shell.execute_reply":"2024-10-09T12:14:04.625438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#putting it all together\n\nann_without = build_net_no_dropout(X_train.shape[1])\nhist_ann_without = model_run(ann_without,X_train,Y_test,Y_train,X_test,30)\nplotter(hist_ann_without, \"msle\")\nplotter(hist_ann_without, \"loss\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:36:04.863461Z","iopub.execute_input":"2024-10-06T23:36:04.864530Z","iopub.status.idle":"2024-10-06T23:36:12.557540Z","shell.execute_reply.started":"2024-10-06T23:36:04.864461Z","shell.execute_reply":"2024-10-06T23:36:12.556628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ann_with = build_net_with_dropout(X_train.shape[1])\nhist_ann_with = model_run(ann_with,X_train,Y_test,Y_train,X_test,40)\nplotter(hist_ann_with, \"msle\")\nplotter(hist_ann_with, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:38.357084Z","iopub.execute_input":"2024-10-06T21:51:38.357557Z","iopub.status.idle":"2024-10-06T21:51:45.076288Z","shell.execute_reply.started":"2024-10-06T21:51:38.357514Z","shell.execute_reply":"2024-10-06T21:51:45.075364Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nPredictions = ann_without.predict(X_test)\nReal = Y_test\ndft = pd.DataFrame({\"real_2017\":list(Y_test),\"Prediction_2017\":list(Predictions)})\nplt.figure(figsize =(20,4))\nplt.plot(dft[\"real_2017\"])\nplt.plot(dft[\"Prediction_2017\"])\nplt.legend([\"Real\", \"Predictions\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:36:48.485212Z","iopub.execute_input":"2024-10-06T23:36:48.485589Z","iopub.status.idle":"2024-10-06T23:36:48.847362Z","shell.execute_reply.started":"2024-10-06T23:36:48.485560Z","shell.execute_reply":"2024-10-06T23:36:48.846335Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#(number,name, k, cap,pointlist,depots,pointx=[],index=-1,refinery=False, allx=points.copy()\n\ndepots,pointx = make_components(25,\"depot_location\",80, 20000,pointx =points.copy())\ndep_points = [q.point for q in depots]\ndep_index =[points.index(q)for q in dep_points]\nrefineries,unused_depots,refpointx = make_refinery(5,\"refinery_location\",5, 100000,dep_index.copy(),pointx)\nusage(points,depots,refineries)    ","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:17:12.533183Z","iopub.execute_input":"2024-10-12T07:17:12.533612Z","iopub.status.idle":"2024-10-12T07:17:17.438702Z","shell.execute_reply.started":"2024-10-12T07:17:12.533576Z","shell.execute_reply":"2024-10-12T07:17:17.437035Z"},"trusted":true,"scrolled":true},"outputs":[{"name":"stdout","text":"done\ncurrent avail dept: [1501, 233, 1836, 1327, 570, 763, 2042, 1215, 313, 1253, 1264, 2396, 187, 1080, 1011, 2250, 276, 971, 1969, 1575, 159, 212, 498, 1540, 1788]\ncurrent avail dept: [1501, 233, 1327, 2042, 1215, 313, 1253, 1264, 2396, 187, 1011, 2250, 276, 971, 1969, 1575, 159, 212, 498, 1788]\ncurrent avail dept: [1501, 233, 1327, 2042, 1253, 1264, 2396, 1011, 2250, 276, 971, 1969, 1575, 212, 1788]\ncurrent avail dept: [1501, 233, 1327, 1253, 2396, 2250, 971, 1969, 1575, 1788]\ncurrent avail dept: [1501, 233, 2396, 2250, 971]\ndone\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m dep_index \u001b[38;5;241m=\u001b[39m[points\u001b[38;5;241m.\u001b[39mindex(q)\u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m dep_points]\n\u001b[1;32m      6\u001b[0m refineries,unused_depots,refpointx \u001b[38;5;241m=\u001b[39m make_refinery(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefinery_location\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m100000\u001b[39m,dep_index\u001b[38;5;241m.\u001b[39mcopy(),pointx)\n\u001b[0;32m----> 7\u001b[0m \u001b[43musage\u001b[49m(points,depots,refineries)    \n","\u001b[0;31mNameError\u001b[0m: name 'usage' is not defined"],"ename":"NameError","evalue":"name 'usage' is not defined","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"# each additional component in the waste to energy supply chain will be represented \n\nclass Component():\n    def __init__(self, index, name, num, cap,k,pointx,refinery, data=biomass.copy(),distance = distance.copy(),spare =points.copy(),sources=None):\n        self.name = name\n        self.index = index\n        self.num = num       \n        self.capacity = cap\n        self.is_ref = refinery\n        self.tree = rtree.index.Rtree()\n        self.point = spare[index]\n        \n        self.pointx = pointx.copy()\n            \n    \n        if refinery==True and sources!=  None:\n            self.depot_left = sources.copy()\n            for i,a in enumerate(sources):# sources should be index numbers\n                p=spare[a]\n                self.tree.insert(i,p+p,p)\n                \n        else:\n            for i,p in enumerate(pointx):\n                self.tree.insert(i,p+p,p)\n            \n       \n            \n        \n        # k nearest point\n        self.sources= list(self.tree.nearest(self.point, k+1,objects='raw' ))\n        if len(self.sources)>k+1:\n            self.sources = self.sources[:k+1]\n        \n        self.sources = self.sources.copy()[1:]      \n        #print(len(self.sources))\n        self.sources_index = []\n        if self.is_ref ==False:\n            for i in self.sources:\n                self.sources_index.append(spare.index(i))\n            \n        else: \n            for i in self.sources:\n                self.sources_index.append(spare.index(i))\n               \n            \n        #print(\"Original number of sources {}\".format(len(self.sources)))\n        \n        #this part calculates the total output of the sources\n        if self.is_ref==False:\n            sources_output = data[\"2017\"][self.sources_index].sum()\n        \n            self.under_util = 0\n            if sources_output>self.capacity and self.is_ref == False:\n                while True:\n                    lee = data[\"2017\"][self.sources_index].values\n                    minx = np.argmin(lee, axis = 0)\n                    self.sources.pop(minx)\n                    self.sources_index.pop(minx)\n                    sources_output = data[\"2017\"][self.sources_index].sum()\n                \n                    if sources_output<=self.capacity:\n                        self.under_util = self.capacity-sources_output\n                        break\n                    else:\n                        continue\n                for i in self.sources:\n                    self.pointx.remove(i)\n            \n                \n                    \n            self.sources_output = sources_output \n        \n         \n        \n        \n        self.sources_index = [spare.index(i) for i in self.sources.copy()]\n        self.total_dist = 0\n        for i in self.sources_index:\n            self.total_dist+=distance.iloc[i,self.index]\n        \n        #print(\"final number of sources {}\".format(len(self.sources)))\n        \n    def prevent_duplicates(self):\n        if self.is_ref ==True:\n            depot_left = self.depot_left\n            for iw in self.sources_index:\n                depot_left.remove(iw)\n            del(self.depot_left)\n            return self.pointx,depot_left\n        else:\n            return self.pointx\n            \n    def add(self,df):\n        q= int(self.index)\n        df.Type[q] = str(self.name)\n        return df\n    def output(self):\n        return self.sources_output\n    def cost(self):\n        return self.total_dist,self.under_util\n    \n            \n        \n        \n\ndef make_refinery(number,name, k, cap,depots,pointx,index=-1,refinery=True, allx=points.copy()):\n    \n    refineries = [] \n    if index==-1:        \n        listr = [] \n        \n        for i in range(number):\n            index = allx.index(random.choice(pointx))\n            \n            if index not in listr :\n                pointx.remove(allx[index])\n                print(\"current avail dept: {}\".format(depots))\n                comp = Component(index,name,i,cap,k,pointx.copy(),refinery = refinery,sources=depots.copy())\n                pointx,depots= comp.prevent_duplicates()\n                refineries.append(comp)\n                listr.append(index)\n                \n            else:\n                i = i-1\n                continue\n    print(\"done\")\n    return refineries.copy(),depots.copy(),pointx.copy()   \n\ndef make_components(number,name, k, cap,pointx,index=-1,refinery=False, allx = points.copy()):\n    components = [] \n    if index==-1:        \n        listr = [] \n        for i in range(number):\n            index = allx.index(random.choice(pointx))\n            if index not in listr:\n                #print (pointx)\n                pointx.remove(allx[index])\n        \n                comp = Component(index,name,i,cap,k,pointx.copy(),refinery = refinery)\n                pointx= comp.prevent_duplicates()\n                components.append(comp)\n                listr.append(index)\n                \n            else:\n                i = i-1\n                continue\n    print(\"done\")\n    return components.copy(),pointx.copy()\n        \n    \n    \n     \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T07:17:06.713231Z","iopub.execute_input":"2024-10-12T07:17:06.713655Z","iopub.status.idle":"2024-10-12T07:17:06.772144Z","shell.execute_reply.started":"2024-10-12T07:17:06.713621Z","shell.execute_reply":"2024-10-12T07:17:06.770884Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"q= np.array([1,4])\nq.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#creating a custom environment with gym\n\nclass Environment(Env):\n    def __init__(self,num_dep,num_refinery, points = points):\n        a = 0.001\n        b = 1\n        c = 1\n        self.k = 80\n        self.points = points \n        self.num_dep = num_dep\n        self.refinery_cap = 100000\n        self.num_refinery = num_refinery\n        self.dep_cap = 20000\n        #new\n        self.depots,self.pointx = make_components(25,\"depot_location\",self.k, self.dep_cap,points)\n        self.dep_points = [q.point for q in self.depots]\n        self.dep_index =[points.index(q)for q in self.dep_points]\n        self.refineries,self.refpointx = make_refinery(5,\"refinery_location\",5, 100000,pointx,self.dep_index)\n        usage(points,depots,refineries)    \n        #new\n        self.ref_points = [q.point for q in self.refineries]\n        self.transport = 0\n        self.underutil = 0\n        self.ndim=(self.num_dep+self.num_refinery,2)\n        self.observation_space = Box(high= np.inf,low = -np.inf,shape = (2,))\n        self.action_space =Discrete(np.prod(self.ndim))\n        for i in self.depots:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        for i in self.refineries:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        self.state = (a*self.transport)+(c*self.underutil)\n        self.episode_len = 100\n        self.use = self.usage()\n        self.previous_score = []\n        self.reinitialize= {\"depots\":self.depots,\n                            \"refinery\":self.refineries, \n                            \"refinery_points\":self.ref_points,\n                            \"depot_points\" :self.dep_points,\n                            \"deppointx\":self.pointx,\n                            'refpoints':self.refpointx,\n                            \"usage\" : self.use\n                           }\n        print(\"utilizing {} percent of all available output\".format(self.use))\n        \n        \n    def usage(self):\n        \n        all_dep_output = [q.sources_output for q in self.depots]\n        print(all_dep_output)\n        all_dep_indexes = [q.index for q in self.depots]\n        all_ref_sources = [q.sources_index for q in self.refineries]\n        all_ref_sources_flat=[]\n        for e in all_ref_sources:\n            for q in e:\n                all_ref_sources_flat.append(q)\n       \n                                   \n        \n        print(\"refinery sources \\n\")\n        \n    \n    \n        \n        total_usage = 0\n        for i in all_ref_sources_flat:\n            if i in all_dep_indexes:\n                pla = all_dep_indexes.index(i)\n                total_usage= total_usage+all_dep_output[pla]\n                print(total_usage)\n        perc = 100*(total_usage/(biomass[\"2017\"].sum()))\n        return perc\n         \n\n        return perc\n            \n        \n        \n            \n        \n        \n    def observe(self):\n        return np.array([self.state,self.use])\n    \n    def reset(self):\n        self.reinitialize[\"depots\"] = self.depots\n        self.reinitialize[\"refinery\"] = self.refineries \n        self.reinitialize[\"refinery_points\"] =self.ref_points\n        self.reinitialize[\"depot_points\"] =self.dep_points\n        self.reinitialize[\"deppointx\"] = self.pointx\n        self.reinitialize['refpoints'] = self.refpointx\n        self.reinitialize[\"usage\"] : self.usage\n        self.episode_len = 100\n        self.previous_score = []\n        self.state = self.recalc()\n        obs = self.observe()\n        return obs\n        \n    def recalc (self):\n        a = 0.001\n        b = 1\n        c = 1\n        self.transport = 0\n        self.underutil = 0\n        for i in self.depots:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        for i in self.refineries:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        var = (a*self.transport)+(c*self.underutil)\n        return var\n        \n    def close(self):\n        pass\n        \n    def step(self, action):\n        reward = 0\n        mapping = tuple(np.ndindex(self.ndim))\n        action = mapping[action]\n        if action[0]>=(self.num_dep) and self.episode_len>0:\n            # if the agent picks from [0, self.num_dep] that indicates a depot, else its a refinery\n            # in this case it is a refinery that has been selected\n            self.episode_len -= 1 \n              #selcting one the final motion [left:0,right:1]                \n            rp = self.ref_points[action[0]-self.num_dep]\n            indx = self.points.index(rp)\n            if action[1] == 0: #left\n                if indx-10>=0:\n                    for i in self.refineries[action[0]-self.num_dep].sources:\n                        self.refpointx.append(i)\n                    self.pointx.append(self.refineries[action[0]-self.num_dep].point)   \n                        \n                    ref_new =Component(indx-10,\"refinery_location\",indx-10,100000,self.dep_points,4,self.refpointx,refinery = True)\n                    self.refpointx = ref_new.prevent_duplicates()\n                    self.refineries[action[0]-self.num_dep] = ref_new\n                    self.ref_points[action[0]-self.num_dep] = ref_new.point \n                    \n                    self.state = self.recalc() \n                else:\n                    reward -= 20\n                    \n            elif action[1] == 1:# right\n                if indx+10<=2417:\n                    for i in self.refineries[action[0]-self.num_dep].sources:\n                        self.refpointx.append(i)\n                    self.pointx.append(self.refineries[action[0]-self.num_dep].point)\n                    ref_new=Component(indx+10,\"refinery_location\",indx+10,100000,self.dep_points,4,self.refpointx,refinery = True)                     \n                    self.refpointx = ref_new.prevent_duplicates()\n                    print(type(ref_new))\n                    self.refineries[action[0]-self.num_dep] =ref_new\n                   \n                    self.ref_points[action[0]-self.num_dep] =ref_new.point \n                    self.state = self.recalc()\n                else:\n                    reward -= 20      \n            \n        elif action[0]<(self.num_dep) and self.episode_len>0:                               #in this case the agent selects a depot\n            self.episode_len -= 1 \n              #selcting one the final motion [left,right]\n            dp = self.dep_points[action[0]]\n            indx = self.points.index(dp)\n            if action[1] == 0: #left\n                \n                \n                if indx-10>=0:\n                    for i in self.depots[action[0]].sources:\n                        self.pointx.append(i)\n                    self.pointx.append(self.depots[action[0]].point)\n                    # this code block is necessary, so we can remove depos from attached refineries\n                    qwe = [q.sources for q in self.refineries]\n                    ins = 0\n                    for qw in qwe:\n                        if self.depots[action[0]].point in qw:\n                            ins = qwe.index(qw)\n                            pox = que[qw].index(self.depots[action[0]].point)\n                            break\n                        else:\n                            continue\n                    \n                    \n                    \n                    dep_new= Component(indx-10,\"depot_location\",indx-10,20000,self.points,self.k,self.pointx,refinery = False)\n                    self.pointx=dep_new.prevent_duplicates() \n                    \n                    self.depots[action[0]] =dep_new\n                    self.dep_points[action[0]] =dep_new.point\n                    \n                    self.refineries[ins].sources[pox] = dep_new.point\n                    self.refineries[ins].sources_index [pox]=dep_new.index\n                \n                    self.state = self.recalc() \n                else:\n                    reward -= 20\n                    \n            elif action[1] == 1:# right\n                if indx+10<=2417:\n                    for i in self.depots[action[0]].sources:\n                        self.pointx.append(i)\n                    self.pointx.append(self.depots[action[0]].point)\n                    # this code block is necessary, so we can remove depos from attached refineries\n                    qwe = [q.sources for q in self.refineries]\n                    ins =0\n                    pox = 0\n                    for qw in qwe:\n                        if self.depots[action[0]].point in qw:\n                            ins = qwe.index(qw)\n                            pox = que[qw].index(self.depots[action[0]].point)\n                            break\n                        else:\n                            continue\n                    \n                    \n                    dep_new = Component(indx+10,\"depot_location\",indx+10,20000,self.points,self.k,self.pointx,refinery = False)                    \n                    self.pointx=dep_new.prevent_duplicates() \n                    self.depots[action[0]] =dep_new\n                    self.dep_points[action[0]] =dep_new.point\n                    self.refineries[ins].sources[pox] = dep_new.point\n                    self.refineries[ins].sources_index [pox]=dep_new.index\n                    \n                    \n                    \n                    \n                    self.state = self.recalc() \n                else:\n                    reward -= 20\n                    \n                    \n                \n        \n        # Calculating the reward\n        if len(self.previous_score)>0:\n            reward += (20*(self.previous_score[-1]-self.state))/self.previous_score[-1]\n            self.previous_score.append(self.state)\n \n  \n        elif len(self.previous_score)==0:\n            self.previous_score.append(self.state) \n            \n        # additional rewards\n        self.use = self.usage()\n        if self.use<=80:\n            reward+= 9\n        else:\n            reward-=2\n            \n        \n        # Checking if episode is done\n        if self.episode_len <= 0: \n            done = True\n        else:\n            done = False\n        \n        # Setting the placeholder for info\n       \n        info = {'usage':self.use}\n        \n        # Returning the step information\n        return self.observe(), reward, done,info","metadata":{"execution":{"iopub.status.busy":"2024-10-12T05:54:33.185478Z","iopub.execute_input":"2024-10-12T05:54:33.185837Z","iopub.status.idle":"2024-10-12T05:54:33.229374Z","shell.execute_reply.started":"2024-10-12T05:54:33.185806Z","shell.execute_reply":"2024-10-12T05:54:33.228476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Enviro = Environment(23,5)\nstate = Enviro.observation_space.shape\nactions = Enviro.action_space.n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.687065Z","iopub.status.idle":"2024-10-06T21:51:45.687633Z","shell.execute_reply.started":"2024-10-06T21:51:45.687330Z","shell.execute_reply":"2024-10-06T21:51:45.687357Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def usage(points,depots,refineries):\n         \n        all_dep_output = [q.sources_output for q in depots]\n        print(all_dep_output)\n        all_dep_indexes = [q.index for q in depots]\n        all_ref_sources = [q.sources_index for q in refineries]\n        all_ref_sources_flat=[]\n        for e in all_ref_sources:\n            for q in e:\n                all_ref_sources_flat.append(q)\n       \n                                   \n        print(all_dep_indexes)\n        print(\"refinery sources \\n\")\n        \n        print(all_ref_sources_flat)\n    \n        \n        total_usage = 0\n        for i in all_ref_sources_flat:\n            if i in all_dep_indexes:\n                pla = all_dep_indexes.index(i)\n                total_usage= total_usage+all_dep_output[pla]\n                print(total_usage)\n        perc = 100*(total_usage/(biomass[\"2017\"].sum()))\n        return perc","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:17:09.120902Z","iopub.execute_input":"2024-10-09T12:17:09.121313Z","iopub.status.idle":"2024-10-09T12:17:09.129279Z","shell.execute_reply.started":"2024-10-09T12:17:09.121280Z","shell.execute_reply":"2024-10-09T12:17:09.128157Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-07T07:22:21.201590Z","iopub.execute_input":"2024-10-07T07:22:21.201936Z","iopub.status.idle":"2024-10-07T07:22:21.209169Z","shell.execute_reply.started":"2024-10-07T07:22:21.201910Z","shell.execute_reply":"2024-10-07T07:22:21.208239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[q.index for q in Enviro.refineries]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.694168Z","iopub.status.idle":"2024-10-06T21:51:45.694559Z","shell.execute_reply.started":"2024-10-06T21:51:45.694352Z","shell.execute_reply":"2024-10-06T21:51:45.694369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" [q.index for q in Enviro.depots]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.696293Z","iopub.status.idle":"2024-10-06T21:51:45.696649Z","shell.execute_reply.started":"2024-10-06T21:51:45.696484Z","shell.execute_reply":"2024-10-06T21:51:45.696501Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" [q.sources_index for q in Enviro.refineries]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.697710Z","iopub.status.idle":"2024-10-06T21:51:45.698068Z","shell.execute_reply.started":"2024-10-06T21:51:45.697887Z","shell.execute_reply":"2024-10-06T21:51:45.697904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model\nmodel = tf.keras.models.Sequential()    \nmodel.add(tf.keras.layers.Dense(32, activation='relu', input_shape =(1,2)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(actions, activation='linear'))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.698939Z","iopub.status.idle":"2024-10-06T21:51:45.699265Z","shell.execute_reply.started":"2024-10-06T21:51:45.699103Z","shell.execute_reply":"2024-10-06T21:51:45.699119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Enviro.usage","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.700466Z","iopub.status.idle":"2024-10-06T21:51:45.700782Z","shell.execute_reply.started":"2024-10-06T21:51:45.700628Z","shell.execute_reply":"2024-10-06T21:51:45.700644Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef build_agent(model, actions):\n    policy = BoltzmannQPolicy()\n    memory = SequentialMemory(limit=50000, window_length=1)\n    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-2)\n    return dqn","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.702377Z","iopub.status.idle":"2024-10-06T21:51:45.702728Z","shell.execute_reply.started":"2024-10-06T21:51:45.702559Z","shell.execute_reply":"2024-10-06T21:51:45.702576Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[points.index(i) for i in Enviro.dep_points]","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.703589Z","iopub.status.idle":"2024-10-06T21:51:45.703910Z","shell.execute_reply.started":"2024-10-06T21:51:45.703748Z","shell.execute_reply":"2024-10-06T21:51:45.703764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"benv = Environment(25,5)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.705194Z","iopub.status.idle":"2024-10-06T21:51:45.705532Z","shell.execute_reply.started":"2024-10-06T21:51:45.705369Z","shell.execute_reply":"2024-10-06T21:51:45.705385Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Agent = build_agent(model, actions)\nAgent.compile(tf.keras.optimizers.legacy.Adam(learning_rate=1e-2), metrics=['mae'])\nAgent.fit(Enviro , nb_steps=1000, visualize=False, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:45.706606Z","iopub.status.idle":"2024-10-06T21:51:45.706974Z","shell.execute_reply.started":"2024-10-06T21:51:45.706780Z","shell.execute_reply":"2024-10-06T21:51:45.706797Z"},"trusted":true},"outputs":[],"execution_count":null}]}