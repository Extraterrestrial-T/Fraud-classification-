{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":880348,"sourceType":"datasetVersion","datasetId":469408},{"sourceId":6189596,"sourceType":"datasetVersion","datasetId":3552708},{"sourceId":6261649,"sourceType":"datasetVersion","datasetId":3598948},{"sourceId":9687013,"sourceType":"datasetVersion","datasetId":5921847},{"sourceId":142551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":120762,"modelId":143960}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-05T03:02:10.271822Z","iopub.execute_input":"2024-12-05T03:02:10.272203Z","iopub.status.idle":"2024-12-05T03:02:10.324864Z","shell.execute_reply.started":"2024-12-05T03:02:10.272172Z","shell.execute_reply":"2024-12-05T03:02:10.323548Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/initial-arrangment/initial_arangment.pkl\n/kaggle/input/distance/Distance_Matrix.csv\n/kaggle/input/biomass-data/biomass.csv\n/kaggle/input/optimizer1/keras/default/1/shell_v1_optimizer_agent.h5\n/kaggle/input/biomass/Biomass_History.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install keras-rl2\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:18:17.500589Z","iopub.execute_input":"2024-12-05T03:18:17.501406Z","iopub.status.idle":"2024-12-05T03:18:28.988155Z","shell.execute_reply.started":"2024-12-05T03:18:17.501372Z","shell.execute_reply":"2024-12-05T03:18:28.987031Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting keras-rl2\n  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from keras-rl2) (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.51.3)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.9.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.4.13)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (4.6.3)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-rl2) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras-rl2) (0.2.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow->keras-rl2) (1.11.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.3.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->keras-rl2) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.2.2)\nInstalling collected packages: keras-rl2\nSuccessfully installed keras-rl2-1.0.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import plotly.express as px\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.losses import MeanSquaredLogarithmicError,MeanSquaredError,MeanAbsoluteError\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point, MultiPoint\nimport rtree\nfrom sklearn.neighbors import NearestNeighbors\nfrom gym import Env\nfrom gym.spaces import Box, MultiDiscrete, Dict,Discrete\nfrom shapely.ops import nearest_points\nimport geopandas as gpd\nimport seaborn as sns\nimport random\nfrom rl.agents import DQNAgent\nfrom rl.policy import BoltzmannQPolicy\nfrom rl.memory import SequentialMemory\nimport bisect\nimport copy\nimport pickle\nimport pandas as pd\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:18:40.571291Z","iopub.execute_input":"2024-12-05T03:18:40.571784Z","iopub.status.idle":"2024-12-05T03:18:51.872252Z","shell.execute_reply.started":"2024-12-05T03:18:40.571740Z","shell.execute_reply":"2024-12-05T03:18:51.871112Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Data Entry and Point Creation\n","metadata":{}},{"cell_type":"code","source":"biomass = pd.read_csv(\"/kaggle/input/biomass/Biomass_History.csv\")\ndistance = pd.read_csv(\"/kaggle/input/distance/Distance_Matrix.csv\")\n# creating point objects, will be useful later on \npoints = []\nfor i, row in biomass.iterrows():\n    points.append((float(row['Longitude']),float(row[\"Latitude\"])) )\npoints2 = copy.deepcopy(points)\nbiomass[\"Geometries\"] = points\nbiomass[\"Type\"] = \"Biomass prod.plants\"\nprint(biomass.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:18:56.329234Z","iopub.execute_input":"2024-12-05T03:18:56.329932Z","iopub.status.idle":"2024-12-05T03:18:58.314101Z","shell.execute_reply.started":"2024-12-05T03:18:56.329897Z","shell.execute_reply":"2024-12-05T03:18:58.312694Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   Index  Latitude  Longitude       2010       2011       2012       2013  \\\n0      0  24.66818   71.33144   8.475744   8.868568   9.202181   6.023070   \n1      1  24.66818   71.41106  24.029778  28.551348  25.866415  21.634459   \n2      2  24.66818   71.49069  44.831635  66.111168  56.982258  53.003735   \n3      3  24.66818   71.57031  59.974419  80.821304  78.956543  63.160561   \n4      4  24.66818   71.64994  14.653370  19.327524  21.928144  17.899586   \n\n        2014       2015       2016        2017            Geometries  \\\n0  10.788374   6.647325   7.387925    5.180296  (71.33144, 24.66818)   \n1  34.419411  27.361908  40.431847   42.126945  (71.41106, 24.66818)   \n2  70.917908  42.517117  59.181629   73.203232  (71.49069, 24.66818)   \n3  93.513924  70.203171  74.536720  101.067352  (71.57031, 24.66818)   \n4  19.534035  19.165791  16.531315   26.086885  (71.64994, 24.66818)   \n\n                  Type  \n0  Biomass prod.plants  \n1  Biomass prod.plants  \n2  Biomass prod.plants  \n3  Biomass prod.plants  \n4  Biomass prod.plants  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"sns.heatmap(biomass.corr(), annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T20:07:02.317996Z","iopub.execute_input":"2024-10-21T20:07:02.319005Z","iopub.status.idle":"2024-10-21T20:07:03.104007Z","shell.execute_reply.started":"2024-10-21T20:07:02.318964Z","shell.execute_reply":"2024-10-21T20:07:03.102691Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter_mapbox(biomass, lat=\"Latitude\", lon=\"Longitude\",hover_data=[\"Index\"],\n                        color=\"2017\", zoom=3, height=400)\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show(renderer='iframe')","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:19:29.202834Z","iopub.execute_input":"2024-12-05T03:19:29.203944Z","iopub.status.idle":"2024-12-05T03:19:30.933076Z","shell.execute_reply.started":"2024-12-05T03:19:29.203894Z","shell.execute_reply":"2024-12-05T03:19:30.931772Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"420\"\n    src=\"iframe_figures/figure_5.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"biomass[\"2017\"].hist(bins = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:25:55.496673Z","iopub.execute_input":"2024-10-23T11:25:55.497117Z","iopub.status.idle":"2024-10-23T11:25:55.847227Z","shell.execute_reply.started":"2024-10-23T11:25:55.497081Z","shell.execute_reply":"2024-10-23T11:25:55.845761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\n\ndef visualize_depots_refineries_px(depots, refineries, points):\n    # Prepare the data\n    data = []\n    \n    # Loop through depots and their sources\n    for i, depot in enumerate(depots):\n        try:\n            depot_index = depot.index\n            depot_sources = depot.sources_index\n            \n            # Depot itself\n            if depot_index is not None:\n                #print(points[depot_index])\n                data.append({\n                    'Type': f\"Depot {i}\",\n                    'Lat': points[depot_index][1],\n                    'Lon': points[depot_index][0],\n                    'Color': f\"Depot {i}\",\n                    'Marker': 'square'\n                })\n\n            # Sources of the depot\n            for source_index in depot_sources:\n                data.append({\n                    'Type': f\"Depot {i} Source\",\n                    'Lat': points[source_index][1],\n                    'Lon': points[source_index][0],\n                    'Color': f\"Depot {i}\",\n                    'Marker': 'circle'\n                })\n        except Exception as e:\n            print(f\"Error processing depot {i}: {e}\")\n            continue\n\n    # Loop through refineries\n    for i, refinery in enumerate(refineries):\n        try:\n            refinery_index = refinery.index\n            if refinery_index is not None:\n                data.append({\n                    'Type': f\"Refinery {i}\",\n                    'Lat': points[refinery_index][1],\n                    'Lon': points[refinery_index][0],\n                    'Color': 'Refinery',\n                    'Marker': 'cross'\n                })\n        except Exception as e:\n            print(f\"Error processing refinery {i}: {e}\")\n            continue\n\n    # Convert the data into a DataFrame\n    df = pd.DataFrame(data)\n\n    # Create the scatter plot using Plotly Express\n    fig = px.scatter_mapbox(df,\n                            lat='Lat',\n                            lon='Lon',\n                            color='Color',\n                            #symbol='Marker',\n                            hover_name='Type',\n                            zoom=5,\n                            mapbox_style=\"open-street-map\")\n    \n    # Show the plot\n    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n    fig.show(renderer=\"iframe\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:19:57.030623Z","iopub.execute_input":"2024-12-05T03:19:57.031631Z","iopub.status.idle":"2024-12-05T03:19:57.042303Z","shell.execute_reply.started":"2024-12-05T03:19:57.031592Z","shell.execute_reply":"2024-12-05T03:19:57.041136Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"count, bins_count = np.histogram(biomass[\"2017\"], bins=20) \n  \n# finding the PDF of the histogram using count values \npdf = count / sum(count) \n  \n# using numpy np.cumsum to calculate the CDF \n# We can also find using the PDF values by looping and adding \ncdf = np.cumsum(pdf) \n  \n# plotting PDF and CDF \nplt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\") \nplt.plot(bins_count[1:], cdf, label=\"CDF\") \n\nplt.legend() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:27:27.093030Z","iopub.execute_input":"2024-10-23T11:27:27.093562Z","iopub.status.idle":"2024-10-23T11:27:27.368625Z","shell.execute_reply.started":"2024-10-23T11:27:27.093516Z","shell.execute_reply":"2024-10-23T11:27:27.367197Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predictions using neural networks\n\n\"\"\" First a little data prep. We need to batch the results from 2010 till 2016, the 2017 \nresults will serve as the target values for the neural network\"\"\"\n\nx = biomass[[str(i+2000) for i in range(10,17)]].values\nprint(x.shape)\ny = biomass[\"2017\"].values\nprint(y.shape)\nscaler = StandardScaler()\nx = scaler.fit_transform(x)\nX_train,X_test,Y_train,Y_test = train_test_split(x,y, test_size = 0.25, random_state = 32)\nprint (X_train.shape, X_test.shape)\n\n\ndef build_net_no_dropout(input_size):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(input_size,activation = 'relu'))\n    model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(32, activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(1, activation = 'relu'))\n    return model\n\n\ndef build_net_with_dropout(input_size):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(input_size,activation = 'relu',kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(128, activation = \"relu\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.7))\n    model.add(tf.keras.layers.Dense(32, activation = \"relu\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dense(1, activation = 'relu'))\n    return model\n\ndef model_run(model,train_x,val_y, train_y, val_x, num_epochs):\n    loss = MeanSquaredLogarithmicError()\n    optimizer = \"adam\"\n    model.compile( loss= loss, optimizer = optimizer, metrics = [\"msle\"])\n    #training\n    history = model.fit(train_x,train_y, epochs = num_epochs,batch_size= 70, verbose = 1,validation_data = (val_x,val_y))\n    return history\n\ndef plotter(history,metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric])\n    plt.xlabel('Epochs')\n    plt.ylabel(metric)\n    plt.legend([metric,'val_'+metric])\n    plt.show()\n    \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#putting it all together\n\nann_without = build_net_no_dropout(X_train.shape[1])\nhist_ann_without = model_run(ann_without,X_train,Y_test,Y_train,X_test,30)\nplotter(hist_ann_without, \"msle\")\nplotter(hist_ann_without, \"loss\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:36:04.863461Z","iopub.execute_input":"2024-10-06T23:36:04.864530Z","iopub.status.idle":"2024-10-06T23:36:12.557540Z","shell.execute_reply.started":"2024-10-06T23:36:04.864461Z","shell.execute_reply":"2024-10-06T23:36:12.556628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ann_with = build_net_with_dropout(X_train.shape[1])\nhist_ann_with = model_run(ann_with,X_train,Y_test,Y_train,X_test,40)\nplotter(hist_ann_with, \"msle\")\nplotter(hist_ann_with, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2024-10-06T21:51:38.357084Z","iopub.execute_input":"2024-10-06T21:51:38.357557Z","iopub.status.idle":"2024-10-06T21:51:45.076288Z","shell.execute_reply.started":"2024-10-06T21:51:38.357514Z","shell.execute_reply":"2024-10-06T21:51:45.075364Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nPredictions = ann_without.predict(X_test)\nReal = Y_test\ndft = pd.DataFrame({\"real_2017\":list(Y_test),\"Prediction_2017\":list(Predictions)})\nplt.figure(figsize =(20,4))\nplt.plot(dft[\"real_2017\"])\nplt.plot(dft[\"Prediction_2017\"])\nplt.legend([\"Real\", \"Predictions\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-06T23:36:48.485212Z","iopub.execute_input":"2024-10-06T23:36:48.485589Z","iopub.status.idle":"2024-10-06T23:36:48.847362Z","shell.execute_reply.started":"2024-10-06T23:36:48.485560Z","shell.execute_reply":"2024-10-06T23:36:48.846335Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Biomass  Supply chain Optimization\n\nThe goal of this section is to accurately model all components and relationships in the biomass to energy supply chain( site=> biomass depots=> Biomass refinery)and find the best configuration of the that maximizes the utilization of the of available outputs from the the biomass sites. To acheive this objective, we will create objects that model the  component(depots & refineries). In this section we will also format the problem of utilization optimization as a Reinforcement Learning problem and set up a Reinforcement learnning Environmentwhich models a certain configuration that a DQN agent can interact with.","metadata":{}},{"cell_type":"code","source":"# each additional component in the waste to energy supply chain will be represented \n\nclass Component():\n    def __init__(self, index, name, num, cap,k,pointx,refinery, data=biomass.copy(),distance = distance.copy(),spare= copy.deepcopy(points),sources=None):\n        self.name = name\n        self.index = index\n        self.num = num       \n        self.capacity = cap\n        self.is_ref = refinery\n        self.tree = rtree.index.Rtree()\n        self.point = spare[index]\n        \n        self.pointx = copy.deepcopy(pointx)\n            \n    \n        if refinery==True and sources!=  None:\n            self.depot_left = sources.copy()\n            for i,a in enumerate(sources):# sources should be index numbers\n                p=spare[a]\n                self.tree.insert(i,p+p,p)\n                \n        else:\n            for i,p in enumerate(self.pointx):\n                self.tree.insert(i,p+p,p)\n            \n       \n        #print(len(self.pointx)) \n        \n        # k nearest point\n        self.sources= list(self.tree.nearest(self.point, k+1,objects='raw' ))\n        if len(self.sources)>k+1:\n            self.sources = self.sources[:k+1]\n        \n        self.sources = self.sources.copy()[1:]      \n        #print(len(self.sources))\n        self.sources_index = []\n        if self.is_ref ==False:\n            for i in self.sources:\n                self.sources_index.append(spare.index(i))\n            \n        else: \n            for i in self.sources:\n                self.sources_index.append(spare.index(i))\n               \n            \n        #print(\"Original number of sources {}\".format(len(self.sources)))\n        \n        #this part calculates the total output of the sources\n        if self.is_ref==False:\n            sources_output = data[\"2017\"][self.sources_index].sum()\n        \n            self.under_util = 0\n            if sources_output>self.capacity and self.is_ref == False:\n                while True:\n                    lee = data[\"2017\"][self.sources_index].values\n                    minx = np.argmin(lee, axis = 0)\n                    self.sources.pop(minx)\n                    self.sources_index.pop(minx)\n                    sources_output = data[\"2017\"][self.sources_index].sum()\n                \n                    if sources_output<=self.capacity:\n                        self.under_util = self.capacity-sources_output\n                        break\n                    else:\n                        continue\n                \n            if self.is_ref==False:    \n                for i in self.sources:\n                    self.pointx.remove(i)\n                \n            \n                \n            #print(len(self.pointx))        \n            self.sources_output = sources_output \n        \n         \n    \n        \n        self.sources_index = [spare.index(i) for i in self.sources.copy()]\n        self.total_dist = 0\n        for i in self.sources_index:\n            self.total_dist+=distance.iloc[i,self.index]\n        \n        #print(\"final number of sources {}\".format(len(self.sources)))\n        \n    def prevent_duplicates(self):\n        if self.is_ref ==True:\n            depot_left = self.depot_left\n            for iw in self.sources_index:\n                depot_left.remove(iw)\n            del(self.depot_left)\n            return self.pointx,depot_left\n        else:\n            return self.pointx\n            \n    def add(self,df):\n        q= int(self.index)\n        df.Type[q] = str(self.name)\n        return df\n    def output(self):\n        return self.sources_output\n    def cost(self):\n        if self.is_ref ==True:\n            return self.total_dist\n        else:\n            return self.total_dist,self.under_util\n    \n            \n        \n        \n\ndef make_refinery(number,name, k, cap,depots,pointx,index=-1,refinery=True, allx=points.copy()):\n    \n    refineries = [] \n    if index==-1:        \n        listr = [] \n        \n        for i in range(number):\n            index = allx.index(random.choice(pointx))\n            \n            if index not in listr :\n                pointx.remove(allx[index])\n                \n                #print(\"current avail dept: {}\".format(depots))\n                comp = Component(index,name,i,cap,k,copy.deepcopy(pointx),refinery = refinery,sources=copy.deepcopy(depots))\n                pointx,depots= comp.prevent_duplicates()\n                refineries.append(comp)\n                listr.append(index)\n                \n            else:\n                i = i-1\n                continue\n    print(\"done\")\n    return  copy.deepcopy(refineries),copy.deepcopy(depots),copy.deepcopy(pointx)   \n\ndef make_components(number,name, k, cap,pointx,index=-1,refinery=False, allx = points.copy()):\n    components = [] \n    if index==-1:        \n        listr = [] \n        for i in range(number):\n            index = allx.index(random.choice(pointx))\n            if index not in listr:\n                #print (pointx)\n                pointx.remove(allx[index])\n                comp = Component(index,name,i,cap,k,copy.deepcopy(pointx),refinery = refinery)\n                pointx= comp.prevent_duplicates()\n                components.append(comp)\n                listr.append(index)\n                \n            else:\n                i = i-1\n                continue\n    print(\"done\")\n    return copy.deepcopy(components),copy.deepcopy(pointx)\n        \n    \n    \n     \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:55:44.961255Z","iopub.execute_input":"2024-12-05T03:55:44.961664Z","iopub.status.idle":"2024-12-05T03:55:45.028361Z","shell.execute_reply.started":"2024-12-05T03:55:44.961630Z","shell.execute_reply":"2024-12-05T03:55:45.026371Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"\nThis custom reinforcement learning Environment has been engineered to incentivize actions that subsequently lead to lower costs(represented by the Evironment.state variable) and higher resource utilization. Each depot will be supplied by a maximum of 80 other biomass sites and has a capacity of 20,0000  while, each refinery can only be supplied by 5 depots and have a maximum capacity of 100,000. The Environment arrange ment is randomly initialized and so the initial values for cost and utilization will vary. I noticed that DQN agent performs significantly better in Environments with an initial  utilisation greater than or equal to 80%. Based on these finding to ensure best results I recomend that:\n1. Only environments with initial utilization <80% be used to train the agent\n2. Enronments that meet the above criterion should be picked as the model will only be able to optimize the exact enviromnment it was trained on.\n\nIn each step in this environment, the agent can select either a Depot or refinery and, move the selected component to a new unused site to the left or right. The dataset contains 2417 locations from which the optimal sites for the Refineries and Depots must be chosen.  \n","metadata":{}},{"cell_type":"code","source":"#creating a custom environment with gym\n\nclass Environment(Env):\n    def __init__(self,num_dep,num_refinery, points = copy.deepcopy(points)):\n        a = 0.001\n        b = 1\n        c = 1\n        self.k = 80\n        self.points = points \n        self.num_dep = num_dep\n        self.refinery_cap = 100000\n        self.num_refinery = num_refinery\n        self.dep_cap = 20000\n        #new\n        \n        self.depots,self.pointx = make_components(self.num_dep,\"depot_location\",self.k, self.dep_cap,self.points.copy())\n        print(len(self.pointx))\n        self.dep_points = [q.point for q in self.depots]\n        self.dep_index =[points.index(q)for q in self.dep_points]\n        #(number,name, k, cap,depots,pointx,index=-1,refinery=True, allx=points.copy())\n        self.refineries,self.unused_depots,self.pointx = make_refinery(self.num_refinery,\"refinery_location\",5, 100000,copy.deepcopy(self.dep_index),copy.deepcopy(self.pointx))\n        print(len(self.pointx)) \n        #new\n        self.ref_points = [q.point for q in self.refineries]\n        self.transport = 0\n        self.underutil = 0\n        self.ndim=(self.num_dep+self.num_refinery-1,2)\n        self.observation_space = Box(high= np.inf,low = -np.inf,shape = (2,))\n        self.action_space =Discrete(np.prod(self.ndim))\n        all_dep_output = [q.sources_output for q in self.depots.copy()]\n        all_dep_indexes = [q.index for q in self.depots.copy()]\n        for i in self.depots:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n            \n        for i in self.refineries:\n            use = 0\n            for b in i.sources_index:\n                use+= all_dep_output[all_dep_indexes.index(b)]\n            un = 100000-use\n            tr = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        self.state = (a*self.transport)+(c*self.underutil)\n        self.episode_len = 200\n        self.use = self.usage()\n        self.previous_score = []\n        self.reinitialize= {\"depots\":copy.deepcopy(self.depots),\n                            \"refinery\":copy.deepcopy(self.refineries), \n                            \"refinery_points\":copy.deepcopy(self.ref_points),\n                            \"depot_points\" :copy.deepcopy(self.dep_points),\n                            \"pointx\":copy.deepcopy(self.pointx),\n                            'Unused_depots':copy.deepcopy(self.unused_depots),\n                            \"usage\" : copy.deepcopy(self.use),\n                            \"state\": copy.deepcopy(self.state)\n                           }\n        print(\"utilizing {} percent of all available output\".format(self.use))\n        \n        \n    def usage(self):\n        \n        all_dep_output = [q.sources_output for q in self.depots]\n        #print(all_dep_output)\n        all_dep_indexes = [q.index for q in self.depots]\n        all_ref_sources = [q.sources_index for q in self.refineries]\n        all_ref_sources_flat=[]\n        for e in all_ref_sources:\n            for q in e:\n                all_ref_sources_flat.append(q)\n    \n        \n        total_usage = 0\n        for i in all_ref_sources_flat:\n            if i in all_dep_indexes:\n                pla = all_dep_indexes.index(i)\n                total_usage= total_usage+all_dep_output[pla]\n                #print(total_usage)\n        perc = 100*(total_usage/(biomass[\"2017\"].sum()))\n        return perc\n         \n\n    \n            \n    def move_depot(self, old_dep, new_dep_index, selection, attached_ref_pos, attached_ref):\n        # Decompose and rebuild depot at new position\n        self.pointx.extend(old_dep.sources + [old_dep.point])\n        self.pointx.remove(self.points[new_dep_index])\n\n        new_dep = Component(new_dep_index, \"depot_location\", old_dep.num, 20000, self.k, self.pointx.copy(), refinery=False)\n        self.pointx = new_dep.prevent_duplicates()\n        self.depots[selection] = new_dep\n\n        # Update refinery with new depot source\n        self.refineries[attached_ref_pos].sources_index.append(new_dep_index)\n        self.refineries[attached_ref_pos].sources.append(new_dep.point)\n\n        # Remove old depot from refinery\n        self.refineries[attached_ref_pos].sources.remove(old_dep.point)\n       # self.refineries[attached_ref_pos].sources_index.remove(old_dep.index)\n        self.state = self.recalc()\n        \n            \n        \n        \n    def observe(self):\n        return np.array([self.state,self.use])\n    \n    def reset(self):\n        self.depots = self.reinitialize[\"depots\"]\n        self.refineries = self.reinitialize[\"refinery\"] \n        self.ref_points = self.reinitialize[\"refinery_points\"]\n        self.dep_points= self.reinitialize[\"depot_points\"] \n        self.pointx=self.reinitialize[\"pointx\"]\n        self.unused_depots =self.reinitialize['Unused_depots']\n        self.use = self.reinitialize[\"usage\"]\n        \n        self.episode_len = 200\n        self.previous_score = []\n        self.state = self.recalc()\n        obs = self.observe()\n        return obs\n        \n    def recalc (self):\n        a = 0.001\n        b = 1\n        c = 1\n        self.transport = 0\n        self.underutil = 0\n        all_dep_output = [q.sources_output for q in self.depots.copy()]\n        all_dep_indexes = [q.index for q in self.depots.copy()]\n        for i in self.depots:\n            tr,un = i.cost()\n            self.transport+=tr\n            self.underutil+=un\n        for i in self.refineries:\n            use = 0\n            for b in i.sources_index:\n                use+= all_dep_output[all_dep_indexes.index(b)]\n            un = 100000-use\n            tr = i.cost()\n\n            self.transport+=tr\n            self.underutil+=un\n        var = (a*self.transport)+(c*self.underutil)\n        return var\n        \n    def close(self):\n        pass\n\n    def find_closest(self, target, less=True):\n    # Ensure the list is sorted for binary search\n        lst = [self.points.index(q) for q in copy.deepcopy(self.pointx)]\n        lst.sort()\n\n    # Find the insertion point for the target using bisect\n        pos = bisect.bisect_left(lst, target)\n\n    # If target is found in the list, return it\n        if pos < len(lst) and lst[pos] == target:\n            return lst[pos]\n\n        if less:\n        # Find the closest number less than the target\n            if pos == 0:\n                return None  # No number less than target\n            else:\n                return lst[pos - 1]  # Return the closest smaller number\n        else:\n        # Find the closest number greater than the target\n            if pos == len(lst):\n                return None  # No number greater than target\n            else:\n                return lst[pos]  # Return the closest larger number\n\n\n\n        \n    def step(self, action):\n        reward = 0\n        mapping = tuple(np.ndindex(self.ndim))\n        action = mapping[action]\n        self.episode_len -= 1 \n        if action[0]>=(self.num_dep) and self.episode_len>0:\n            # if the agent picks from [0, self.num_dep] that indicates a depot, else its a refinery\n            # in this case it is a refinery that has been selected\n            selection = action[0]-self.num_dep\n            try:\n                old_ref = self.refineries[selection]\n            except IndexError:\n                print(\" refinery action number{} refinery list length{}\".format(selection,len(self.refineries)))\n                return IndexError\n            old_ref_number = old_ref.num\n            old_ref_index =old_ref.index\n            if action[1] == 0:\n                #moves left\n                new_ref_index = self.find_closest(old_ref_index-10, less=True)\n                if new_ref_index !=None:\n                    self.refineries[selection] = None\n                    #freeing up the old refinery's attached depots\n                    for de in old_ref.sources_index:\n                        self.unused_depots.append(de)\n                    \n                    #Component(index,name,i,cap,k,pointx.copy(),refinery = refinery,sources=depots.copy())\n                    new_ref = Component(new_ref_index,\"refinery_location\",old_ref_number,100000,5,self.pointx,refinery=True,sources=self.unused_depots)\n                    self.pointx.remove(new_ref.point)\n                    self.pointx,self.unused_depots = new_ref.prevent_duplicates()\n                    self.pointx.append(old_ref.point)\n                    self.refineries[selection] =  new_ref\n                    self.state= self.recalc()\n                else:\n                    reward-=4\n                \n                    \n                \n            elif action[1] ==1:\n                #moves right\n                new_ref_index = self.find_closest(old_ref_index+10, less=False)\n                if new_ref_index !=None:\n                    self.refineries[selection] = None\n                    #freeing up the old refinery's attached depots\n                    for de in old_ref.sources_index:\n                        self.unused_depots.append(de)\n                    \n                    #Component(index,name,i,cap,k,pointx.copy(),refinery = refinery,sources=depots.copy())\n                    new_ref = Component(new_ref_index,\"refinery_location\",old_ref_number,100000,5,self.pointx,refinery=True,sources=self.unused_depots)\n                    self.pointx.remove(new_ref.point)\n                    self.pointx,self.unused_depots = new_ref.prevent_duplicates()\n                    self.pointx.append(old_ref.point)\n                    self.refineries[selection] =  new_ref\n                    self.state= self.recalc()\n                else:\n                    reward-=4\n\n            \n        \n        elif action[0]>self.num_dep and self.episode_len>0:\n            # 0 to num_dep-1 is a depot\n            \n            selection = action[0]\n            try:\n                old_dep = self.depots[selection]\n            except IndexError:\n                print(\"action depot{} depot list{}\".format(selection,len(self.depots)))\n                return IndexError\n            old_dep_number = old_dep.num\n            old_dep_index =old_dep.index\n            attached_ref_pos = None\n            attached_ref=None\n            #checking if the depot is linked to any refinery no point moving a depot that is not summ\n            for we in self.refineries:\n                if old_dep_index in we.sources_index:\n                    we.sources_index.remove(old_dep_index)\n                    attached_ref_pos = self.refineries.index(we)\n                    attached_ref = we \n                    break\n                else:\n                    continue\n            if attached_ref !=None: # \n                if action[1] ==1: # right\n                    new_dep_index = self.find_closest(old_dep_index+10, less=False)\n                    if new_dep_index !=None:\n                        self.move_depot(old_dep, new_dep_index, selection, attached_ref_pos, attached_ref)\n                        #self.state = self.recalc()\n\n                    else:\n                        reward-6\n        \n                if action[1] == 0:#left \n                    new_dep_index = self.find_closest(old_dep_index-10, less=True)\n                    if new_dep_index !=None:\n                        self.move_depot(old_dep, new_dep_index, selection, attached_ref_pos, attached_ref)\n                        #self.state = self.recalc()\n\n                    else:\n                        reward-=6\n            else:\n                reward-=6\n                \n            \n            \n        \n        # Calculating the reward\n        if len(self.previous_score)>0:\n            reward += (30*(self.previous_score[-1]-self.state))/self.previous_score[-1]\n            self.previous_score.append(self.state)\n \n  \n        elif len(self.previous_score)==0:\n            self.previous_score.append(self.state) \n            \n        # additional rewards\n        use = self.usage()\n        self.use = use\n        if self.use>=80:\n            reward+= 2*(self.use-80)/80\n        else:\n            reward+=2*(self.use-80)/80\n            \n        \n        # Checking if episode is done\n        if self.episode_len <= 0: \n            done = True\n        else:\n            done = False\n        \n        #Setting the placeholder for info\n       \n        info = {'usage':self.use,\"cost\":self.state}\n        \n        # Returning the step information\n        return self.observe(), reward, done,info","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:54:03.452330Z","iopub.execute_input":"2024-12-05T03:54:03.453227Z","iopub.status.idle":"2024-12-05T03:54:03.513675Z","shell.execute_reply.started":"2024-12-05T03:54:03.453176Z","shell.execute_reply":"2024-12-05T03:54:03.512223Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Run the cell below, mutliple times until you get an environment that satisfies the criteria ","metadata":{}},{"cell_type":"code","source":"Enviro = Environment(25,5)\nstate = Enviro.observation_space.shape\nactions = Enviro.action_space.n","metadata":{"execution":{"iopub.status.busy":"2024-12-05T04:03:46.872068Z","iopub.execute_input":"2024-12-05T04:03:46.872428Z","iopub.status.idle":"2024-12-05T04:03:49.692752Z","shell.execute_reply.started":"2024-12-05T04:03:46.872399Z","shell.execute_reply":"2024-12-05T04:03:49.691683Z"},"trusted":true},"outputs":[{"name":"stdout","text":"done\n586\ndone\n581\nutilizing 81.90351536764538 percent of all available output\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"[i.sources_index for i in Enviro.refineries]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T04:04:06.201641Z","iopub.execute_input":"2024-12-05T04:04:06.202165Z","iopub.status.idle":"2024-12-05T04:04:06.211025Z","shell.execute_reply.started":"2024-12-05T04:04:06.202124Z","shell.execute_reply":"2024-12-05T04:04:06.209685Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[[267, 804, 676, 113, 816],\n [2194, 2220, 2008, 1761, 1495],\n [2282, 1520, 1394, 1684, 1209],\n [1226, 1163, 1139, 1800, 1089],\n [785, 710, 2051, 216]]"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"[i.index for i in Enviro.refineries]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T04:04:21.491483Z","iopub.execute_input":"2024-12-05T04:04:21.491890Z","iopub.status.idle":"2024-12-05T04:04:21.499112Z","shell.execute_reply.started":"2024-12-05T04:04:21.491849Z","shell.execute_reply":"2024-12-05T04:04:21.497800Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[16, 2373, 1969, 2407, 2070]"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def random_steps_in_custom_env(env, num_steps):\n    \n    #state = env.reset()\n    trajectory = []\n\n    for _ in range(num_steps):\n        action = env.action_space.sample()\n        next_state, reward, done, _ = env.step(action)\\\n        print([w.index for w in env.refineries])\n        trajectory.append((state, action, reward, next_state, done))\n        state = env.reset() if done else next_state\n\n    return trajectory\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_steps_in_custom_env(Enviro, 100):\n    ","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_depots_refineries_px(Enviro.depots, Enviro.refineries, points2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T04:04:50.721396Z","iopub.execute_input":"2024-12-05T04:04:50.721769Z","iopub.status.idle":"2024-12-05T04:04:50.872017Z","shell.execute_reply.started":"2024-12-05T04:04:50.721732Z","shell.execute_reply":"2024-12-05T04:04:50.870941Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_29.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"visualize_depots_refineries_px(Enviro.depots, Enviro.refineries, points2)","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:56:19.011729Z","iopub.execute_input":"2024-12-05T03:56:19.012557Z","iopub.status.idle":"2024-12-05T03:56:19.246183Z","shell.execute_reply.started":"2024-12-05T03:56:19.012507Z","shell.execute_reply":"2024-12-05T03:56:19.244646Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_11.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def save_config(name, env):\n     with open(name, \"wb\") as file:\n         pickle.dump(env,file)\n         \ndef load_config (name):\n    with open(name,\"rb\") as file:\n        obj = pickle.load(file)\n        return obj\n    ","metadata":{"execution":{"iopub.status.busy":"2024-12-05T04:05:57.972426Z","iopub.execute_input":"2024-12-05T04:05:57.972919Z","iopub.status.idle":"2024-12-05T04:05:57.979323Z","shell.execute_reply.started":"2024-12-05T04:05:57.972877Z","shell.execute_reply":"2024-12-05T04:05:57.977935Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"save_config(\"80percentuse.pkl\",Enviro)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T04:06:07.631365Z","iopub.execute_input":"2024-12-05T04:06:07.631743Z","iopub.status.idle":"2024-12-05T04:06:07.651310Z","shell.execute_reply.started":"2024-12-05T04:06:07.631712Z","shell.execute_reply":"2024-12-05T04:06:07.650303Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"# Model creation and DQN Training","metadata":{}},{"cell_type":"code","source":"# model\nmodel = tf.keras.models.Sequential()    \nmodel.add(tf.keras.layers.Dense(32, activation='tanh', input_shape =(1,2)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128, activation='tanh'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(128, activation='tanh'))\nmodel.add(tf.keras.layers.Dense(actions, activation='linear'))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:17:59.873199Z","iopub.execute_input":"2024-10-28T20:17:59.874632Z","iopub.status.idle":"2024-10-28T20:18:00.074844Z","shell.execute_reply.started":"2024-10-28T20:17:59.874578Z","shell.execute_reply":"2024-10-28T20:18:00.073048Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\ndef build_agent(model, actions):\n    policy = BoltzmannQPolicy()\n    memory = SequentialMemory(limit=5000000, window_length=1)\n    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n                  nb_actions=actions, nb_steps_warmup=200, target_model_update=1e-3)\n    return dqn\nAgent = build_agent(model, actions)\nAgent.compile(tf.keras.optimizers.legacy.SGD(learning_rate=1e-3), metrics=['mae'])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:39:46.135513Z","iopub.execute_input":"2024-10-28T20:39:46.136045Z","iopub.status.idle":"2024-10-28T20:39:47.100394Z","shell.execute_reply.started":"2024-10-28T20:39:46.136008Z","shell.execute_reply":"2024-10-28T20:39:47.098386Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"\n\nAgent.fit(Enviro , nb_steps=150000, visualize=False, verbose=1)\n\nAgent.save_weights(\"optimizer.h5\", overwrite = False)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T05:11:02.086611Z","iopub.execute_input":"2024-10-21T05:11:02.087076Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Perform the optimization after Training\n\nFor this I will be loading a saved initial configuration and a model that was trained on that environment.\nFeel free to play around with this part ","metadata":{}},{"cell_type":"code","source":"def optimize(model,env, steps,verbose= False):\n    #model should be a dqn agent\n    state =env.observe()\n    env.episode_len = steps\n    if env.episode_len>= steps:\n        for i in range(steps):\n            action = model.forward(state)  # Get the action from the trained agent\n            next_state, reward, done, info = env.step(action)  # Apply action to environment\n            if verbose:\n                print(\"Action Taken:\", action)\n                print(\"Next State:\", next_state)\n                print(\"Reward:\", reward)\n                print(\"Info:\", info)\n    \n            if done:\n                print(\"Episode finished.\")\n                print(\"current utilization: {} current cost: {}\".format(env.use,env.state))\n                break\n                \n    \n            state = next_state\n        print(\"current utilization: {} current cost: {}\".format(env.use,env.state))\n    return env\n            \n            \n         \n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:32:38.562118Z","iopub.execute_input":"2024-10-23T11:32:38.563354Z","iopub.status.idle":"2024-10-23T11:32:38.574292Z","shell.execute_reply.started":"2024-10-23T11:32:38.563267Z","shell.execute_reply":"2024-10-23T11:32:38.572932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #a slight bug made my saved environment not fully revert to initial conditons\ndef Hard_env_reset(env):\n    env.depots = copy.deepcopy(env.reinitialize[\"depots\"])\n    env.refineries = copy.deepcopy(env.reinitialize[\"refinery\"] )\n    env.ref_points = copy.deepcopy(env.reinitialize[\"refinery_points\"])\n    env.dep_points= copy.deepcopy(env.reinitialize[\"depot_points\"])\n    env.pointx= copy.deepcopy(env.reinitialize[\"pointx\"])\n    env.unused_depots = copy.deepcopy(env.reinitialize['Unused_depots'])\n    env.use = copy.deepcopy(env.reinitialize[\"usage\"])\n    return env\n        ","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:18:26.465912Z","iopub.execute_input":"2024-10-28T20:18:26.466491Z","iopub.status.idle":"2024-10-28T20:18:26.476211Z","shell.execute_reply.started":"2024-10-28T20:18:26.466445Z","shell.execute_reply":"2024-10-28T20:18:26.474281Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"env = load_config(r\"/kaggle/input/initial-arrangment/initial_arangment.pkl\")\nenv = Hard_env_reset(env)\nenv.observe()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:20:38.290061Z","iopub.execute_input":"2024-10-28T20:20:38.291401Z","iopub.status.idle":"2024-10-28T20:20:38.541940Z","shell.execute_reply.started":"2024-10-28T20:20:38.291339Z","shell.execute_reply":"2024-10-28T20:20:38.540508Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([1.18311021e+05, 8.06750093e+01])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"#initial utilization\nenv.unused_depots = list(set(env.unused_depots ))","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:31:37.253791Z","iopub.execute_input":"2024-10-28T20:31:37.254369Z","iopub.status.idle":"2024-10-28T20:31:37.262188Z","shell.execute_reply.started":"2024-10-28T20:31:37.254327Z","shell.execute_reply":"2024-10-28T20:31:37.260515Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"Enviro.unused_depots","metadata":{"execution":{"iopub.status.busy":"2024-12-05T03:57:45.391178Z","iopub.execute_input":"2024-12-05T03:57:45.391564Z","iopub.status.idle":"2024-12-05T03:57:45.401508Z","shell.execute_reply.started":"2024-12-05T03:57:45.391533Z","shell.execute_reply":"2024-12-05T03:57:45.400109Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[1739]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"sum([i.output() for i in env.depots])/sum(biomass[\"2017\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:38:45.364113Z","iopub.execute_input":"2024-10-28T20:38:45.364642Z","iopub.status.idle":"2024-10-28T20:38:45.376501Z","shell.execute_reply.started":"2024-10-28T20:38:45.364604Z","shell.execute_reply":"2024-10-28T20:38:45.374453Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0.8366009054937635"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"len([i.index for i in env.depots])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:44:27.649824Z","iopub.execute_input":"2024-10-28T20:44:27.650414Z","iopub.status.idle":"2024-10-28T20:44:27.661651Z","shell.execute_reply.started":"2024-10-28T20:44:27.650369Z","shell.execute_reply":"2024-10-28T20:44:27.659751Z"},"trusted":true},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"25"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"[i.sources_index for i in env.refineries]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:45:14.778355Z","iopub.execute_input":"2024-10-28T20:45:14.779377Z","iopub.status.idle":"2024-10-28T20:45:14.791205Z","shell.execute_reply.started":"2024-10-28T20:45:14.779315Z","shell.execute_reply":"2024-10-28T20:45:14.789805Z"},"trusted":true},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[[1525, 1525, 1525, 1525, 1525],\n [379, 379, 379, 379, 379],\n [1745, 1745, 1745, 1745, 1745],\n [1525, 1525, 1525, 1525, 1525],\n [2211, 1953, 2384, 1788]]"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"#initial cost\nenv.recalc()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:34:26.213549Z","iopub.execute_input":"2024-10-23T11:34:26.214958Z","iopub.status.idle":"2024-10-23T11:34:26.222975Z","shell.execute_reply.started":"2024-10-23T11:34:26.214911Z","shell.execute_reply":"2024-10-23T11:34:26.221592Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_depots_refineries_px(env.depots, env.refineries, points2)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:35:04.331819Z","iopub.execute_input":"2024-10-23T11:35:04.332269Z","iopub.status.idle":"2024-10-23T11:35:04.568967Z","shell.execute_reply.started":"2024-10-23T11:35:04.332235Z","shell.execute_reply":"2024-10-23T11:35:04.567367Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#load model\nAgent.load_weights(\"/kaggle/input/optimizer1/keras/default/1/shell_v1_optimizer_agent.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T20:39:20.993216Z","iopub.execute_input":"2024-10-28T20:39:20.993786Z","iopub.status.idle":"2024-10-28T20:39:21.056096Z","shell.execute_reply.started":"2024-10-28T20:39:20.993743Z","shell.execute_reply":"2024-10-28T20:39:21.053684Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#load model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mAgent\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/optimizer1/keras/default/1/shell_v1_optimizer_agent.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'Agent' is not defined"],"ename":"NameError","evalue":"name 'Agent' is not defined","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"env =optimize(Agent,env,200)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:36:22.173633Z","iopub.execute_input":"2024-10-23T11:36:22.174154Z","iopub.status.idle":"2024-10-23T11:36:22.602742Z","shell.execute_reply.started":"2024-10-23T11:36:22.174114Z","shell.execute_reply":"2024-10-23T11:36:22.601190Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_depots_refineries_px(env.depots, env.refineries, points2)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:38:10.228433Z","iopub.execute_input":"2024-10-23T11:38:10.228935Z","iopub.status.idle":"2024-10-23T11:38:10.429794Z","shell.execute_reply.started":"2024-10-23T11:38:10.228898Z","shell.execute_reply":"2024-10-23T11:38:10.428352Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_config(\"bestcase.pkl\",env)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T22:23:14.546888Z","iopub.execute_input":"2024-10-21T22:23:14.547829Z","iopub.status.idle":"2024-10-21T22:23:14.574441Z","shell.execute_reply.started":"2024-10-21T22:23:14.547770Z","shell.execute_reply":"2024-10-21T22:23:14.573147Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-23T10:20:04.621913Z","iopub.execute_input":"2024-10-23T10:20:04.622344Z","iopub.status.idle":"2024-10-23T10:20:04.638614Z","shell.execute_reply.started":"2024-10-23T10:20:04.622313Z","shell.execute_reply":"2024-10-23T10:20:04.637404Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_depots_refineries_px(Enviro.depots, Enviro.refineries, points2)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T10:22:24.036591Z","iopub.execute_input":"2024-10-23T10:22:24.037427Z","iopub.status.idle":"2024-10-23T10:22:24.266357Z","shell.execute_reply.started":"2024-10-23T10:22:24.037389Z","shell.execute_reply":"2024-10-23T10:22:24.265002Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}