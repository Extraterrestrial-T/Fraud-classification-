{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-18T16:11:33.628676Z","iopub.execute_input":"2023-09-18T16:11:33.629071Z","iopub.status.idle":"2023-09-18T16:11:34.699615Z","shell.execute_reply.started":"2023-09-18T16:11:33.629041Z","shell.execute_reply":"2023-09-18T16:11:34.698409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report,confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import f_oneway\nimport tensorflow as tf\nimport random\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:11:40.682915Z","iopub.execute_input":"2023-09-18T16:11:40.683486Z","iopub.status.idle":"2023-09-18T16:11:54.567779Z","shell.execute_reply.started":"2023-09-18T16:11:40.683452Z","shell.execute_reply":"2023-09-18T16:11:54.566620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/fraud-detection-datafest/Copy of FraudDetectionDataset.csv\")\ndata_copy = data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:31:07.145686Z","iopub.execute_input":"2023-09-18T16:31:07.146133Z","iopub.status.idle":"2023-09-18T16:32:01.785520Z","shell.execute_reply.started":"2023-09-18T16:31:07.146099Z","shell.execute_reply":"2023-09-18T16:32:01.784250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:06:11.246123Z","iopub.execute_input":"2023-09-18T16:06:11.246549Z","iopub.status.idle":"2023-09-18T16:06:11.257080Z","shell.execute_reply.started":"2023-09-18T16:06:11.246517Z","shell.execute_reply":"2023-09-18T16:06:11.255723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization and Feature Engineering**","metadata":{}},{"cell_type":"code","source":"numeric_features  =['Transaction ID','User ID','Transaction Amount',\n                    'Merchant ID','User Age','User Income','Location Distance',\n                    'Time Taken for Transaction',\"User's Transaction History\",\n                    \"Merchant's Reputation Score\",\"User's Credit Score\",\n                    \"Merchant's Business Age\"] \n\nall_features = ['Transaction ID', 'User ID', 'Transaction Amount',\n       'Transaction Date and Time', 'Merchant ID', 'Payment Method',\n       'Country Code', 'Transaction Type', 'Device Type',\n       'Browser Type', 'Operating System', 'Merchant Category', 'User Age',\n       'User Occupation', 'User Income', 'User Gender', 'User Account Status',\n       'Transaction Status', 'Location Distance', 'Time Taken for Transaction',\n       'Transaction Time of Day', \"User's Transaction History\",\n       \"Merchant's Reputation Score\", \"User's Device Location\",\n       'Transaction Currency', 'Transaction Purpose', \"User's Credit Score\",\n       \"User's Email Domain\", \"Merchant's Business Age\",\n       'Transaction Authentication Method']\ncategorical_features = list(set(all_features)-set(numeric_features))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:14:05.884059Z","iopub.execute_input":"2023-09-18T16:14:05.884531Z","iopub.status.idle":"2023-09-18T16:14:05.892783Z","shell.execute_reply.started":"2023-09-18T16:14:05.884499Z","shell.execute_reply":"2023-09-18T16:14:05.891334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[numeric_features].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:17:32.343682Z","iopub.execute_input":"2023-09-17T20:17:32.344650Z","iopub.status.idle":"2023-09-17T20:17:34.715050Z","shell.execute_reply.started":"2023-09-17T20:17:32.344619Z","shell.execute_reply":"2023-09-17T20:17:34.713522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[categorical_features].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:17:48.812598Z","iopub.execute_input":"2023-09-17T20:17:48.812977Z","iopub.status.idle":"2023-09-17T20:18:06.899149Z","shell.execute_reply.started":"2023-09-17T20:17:48.812946Z","shell.execute_reply":"2023-09-17T20:18:06.897637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=data, x=\"Fraudulent Flag\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:35:50.318133Z","iopub.execute_input":"2023-09-17T20:35:50.319429Z","iopub.status.idle":"2023-09-17T20:35:50.809531Z","shell.execute_reply.started":"2023-09-17T20:35:50.319365Z","shell.execute_reply":"2023-09-17T20:35:50.808777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting the  categorical variables to numbers\n\ndef convert(data,columns):\n    allmap ={}\n    for i in columns:\n        unique = list(data[i].unique())\n        mapdict ={}\n        for p,u in enumerate(unique):\n            mapdict[u]=p \n        data[i]=data[i].map(mapdict)\n        print(\"done with:{}\".format(i))\n        allmap[i]= mapdict\n    return mapdict\nlookup_table= convert(data,categorical_features)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:18:57.274134Z","iopub.execute_input":"2023-09-17T20:18:57.274507Z","iopub.status.idle":"2023-09-17T20:19:23.789058Z","shell.execute_reply.started":"2023-09-17T20:18:57.274474Z","shell.execute_reply":"2023-09-17T20:19:23.788335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, q in enumerate(categorical_features[0:10]):\n    plt.figure(figsize=(20,7))\n    sns.scatterplot(data=data, x=q, y=\"Fraudulent Flag\")\n    print (i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:25:55.788168Z","iopub.execute_input":"2023-09-17T20:25:55.788576Z","iopub.status.idle":"2023-09-17T20:27:35.175446Z","shell.execute_reply.started":"2023-09-17T20:25:55.788542Z","shell.execute_reply":"2023-09-17T20:27:35.173936Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# investigating categories in fradulent transactions\n\nfor i, q in enumerate(categorical_features[0:12]):\n    plt.figure(figsize=(20,7))\n    dat_fraud =data[(data[\"Fraudulent Flag\"]==1)][q]\n    sns.distplot(dat_fraud )\n    print (i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:30:17.678573Z","iopub.execute_input":"2023-09-17T20:30:17.678995Z","iopub.status.idle":"2023-09-17T20:32:24.612439Z","shell.execute_reply.started":"2023-09-17T20:30:17.678961Z","shell.execute_reply":"2023-09-17T20:32:24.611095Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From all indications this the Fradulent cases appear to be uniformly distrbuted between the various classes in the categorical columns of the dataset with almost no glaring predictors**","metadata":{}},{"cell_type":"code","source":"# investigating categories in non-fradulent transactions\n\nfor i, q in enumerate(categorical_features[0:12]):\n    plt.figure(figsize=(20,7))\n    dat_fraud =data[(data[\"Fraudulent Flag\"]==0)][q]\n    sns.distplot(dat_fraud )\n    print (i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T20:40:45.532756Z","iopub.execute_input":"2023-09-17T20:40:45.533143Z","iopub.status.idle":"2023-09-17T20:42:54.016359Z","shell.execute_reply.started":"2023-09-17T20:40:45.533111Z","shell.execute_reply":"2023-09-17T20:42:54.015116Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From all indications this the non fradulent cases appear to be uniformly distrbuted between the various classes in the categorical columns just like we saw in the fradulent one**","metadata":{}},{"cell_type":"markdown","source":"# Data preparation and categorical preprocessing with Target Encoding ","metadata":{}},{"cell_type":"code","source":"from category_encoders import TargetEncoder\nencodeX= data.sample(frac=0.548, random_state=945)\nencodeY= encodeX[\"Fraudulent Flag\"]\nfor cla in categorical_features:\n    encoder = TargetEncoder()\n    encoder.fit(encodeX[cla], encodeY)\n    data[cla] = encoder.transform(data[cla])","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:14:19.642711Z","iopub.execute_input":"2023-09-18T16:14:19.643140Z","iopub.status.idle":"2023-09-18T16:16:55.338046Z","shell.execute_reply.started":"2023-09-18T16:14:19.643109Z","shell.execute_reply":"2023-09-18T16:16:55.336740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:44:23.554909Z","iopub.execute_input":"2023-09-18T15:44:23.555346Z","iopub.status.idle":"2023-09-18T15:44:23.586417Z","shell.execute_reply.started":"2023-09-18T15:44:23.555314Z","shell.execute_reply":"2023-09-18T15:44:23.585270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the cell above we created a small sample from the entire datset to fit our encoding model. This is to prevent data leakage.","metadata":{}},{"cell_type":"markdown","source":"# Model Training and Evaluation","metadata":{}},{"cell_type":"markdown","source":" ## Approach 1- Plain Logistic Regression classifier","metadata":{}},{"cell_type":"code","source":"#the Data wil be scaled using Standard Scaler and Dimensionality reduction will be carried out using Princpal Componet Analysis \npca = PCA(n_components=15)\nx= data[all_features]\nScaler = StandardScaler()\nx = Scaler.fit_transform(x)\nx=pca.fit_transform(x)\ny= data[\"Fraudulent Flag\"].values\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state =97)\nclf=LogisticRegression(solver =\"lbfgs\", random_state=23).fit(x_train,y_train)\n\ny_pred = clf.predict(x_test)\nprint(classification_report(y_test,y_pred))\n\nfig, ax =plt.subplots()\nsns.heatmap(confusion_matrix(y_test,y_pred, normalize='true'), annot =True,ax= ax)\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real value\")\nax.set_xlabel(\"predicted value\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:16:55.340364Z","iopub.execute_input":"2023-09-18T16:16:55.340709Z","iopub.status.idle":"2023-09-18T16:17:54.390903Z","shell.execute_reply.started":"2023-09-18T16:16:55.340682Z","shell.execute_reply":"2023-09-18T16:17:54.389443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With this model we get a model that's about 70% accurate at identifying both legitimate and fraudulent transactions","metadata":{}},{"cell_type":"markdown","source":" ## Approach 2- Plain Decision Tree classifier","metadata":{}},{"cell_type":"code","source":"tree=DecisionTreeClassifier(max_depth=7,random_state=1).fit(x_train,y_train)\n\ny_pred3 = tree.predict(x_test)\nprint(classification_report(y_test,y_pred3))\n\nfig, ax =plt.subplots()\nsns.heatmap(confusion_matrix(y_test,y_pred3, normalize='true'), annot =True,ax= ax)\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real value\")\nax.set_xlabel(\"predicted value\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Approach 4- Ridge Regression and grid search","metadata":{}},{"cell_type":"code","source":"#we are iterating over the varioues values for the alpha parameter to pick the best performer\nalphas = list(np.arange(0.01, 0.9, 0.05))\nprint (alphas)\nmodel=[]\naccuracies =[]\nseeds = []\nfor a in alphas:\n    seed =random.randint(1,1000)\n    seeds.append(seed)\n    ridge = RidgeClassifier(alpha =a, random_state=seed, solver=\"saga\").fit(x_train, y_train)\n    y_pred4 =ridge.predict(x_test)\n    print(classification_report(y_test,y_pred4))\n    score =accuracy_score(y_test,y_pred4)\n\n    fig, ax =plt.subplots()\n    sns.heatmap(confusion_matrix(y_test,y_pred4, normalize='true'), annot =True,ax= ax)\n    ax.set_title(\"Confusion Matrix\")\n    ax.set_ylabel(\"Real value\")\n    ax.set_xlabel(\"predicted value\")\n    plt.show()\n    accuracies.append(score)\n    model.append(ridge)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T12:51:36.483012Z","iopub.execute_input":"2023-09-18T12:51:36.483460Z","iopub.status.idle":"2023-09-18T13:13:01.396709Z","shell.execute_reply.started":"2023-09-18T12:51:36.483428Z","shell.execute_reply":"2023-09-18T13:13:01.395478Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After Runnning the grid search we got an accuracy and f1 score of 70% for all values of the hyperparameter alpha basically the same** ","metadata":{}},{"cell_type":"markdown","source":" ## Approach 2- Xgb classifier","metadata":{}},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=970)\nxgb_model.fit(x_train, y_train)\n\ny_pred2 = xgb_model.predict(x_test)\nprint(classification_report(y_test,y_pred2))\n\nfig, ax =plt.subplots()\nsns.heatmap(confusion_matrix(y_test,y_pred2, normalize='true'), annot =True,ax= ax)\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real value\")\nax.set_xlabel(\"predicted value\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T13:13:20.781347Z","iopub.execute_input":"2023-09-18T13:13:20.781759Z","iopub.status.idle":"2023-09-18T13:20:14.370306Z","shell.execute_reply.started":"2023-09-18T13:13:20.781726Z","shell.execute_reply":"2023-09-18T13:20:14.368963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**These results are almost identical to other models. In the next cell we will vary two hyperparameters: learning rate and min child weight to see if they can improve performance **","metadata":{}},{"cell_type":"code","source":"#grid search with Xgb classifier\n# new learning rate range\nlearning_rate_range = np.arange(0.01, 0.2, 0.05)\nfig = plt.figure(figsize=(19, 17))\nidx = 1\nprint(\"Total number of trials:{}\".format(len(np.arange(0, 3, 0.5)*len(learning_rate_range))))\n# grid search for min_child_weight\nfor s, weight in enumerate(np.arange(0, 3, 0.5)):\n    \n    train = []\n    test = []\n    for lr in learning_rate_range:\n        xgb_classifier = xgb.XGBClassifier(objective=\"binary:logistic\",eta = lr, reg_lambda=1, min_child_weight=weight,random_state=900)\n        xgb_classifier.fit(x_train, y_train)\n        train.append(xgb_classifier.score(x_train, y_train))\n        test.append(xgb_classifier.score(x_test, y_test))\n    print(\"done with {} trials\".format(len(learning_rate_range)*(s+1)))\n    fig.add_subplot(3, 3, idx)\n    idx += 1\n    plt.plot(learning_rate_range, train, c='orange', label='Training')\n    plt.plot(learning_rate_range, test, c='m', label='Testing')\n    plt.xlabel('Learning rate')\n    plt.xticks(learning_rate_range)\n    plt.ylabel('Accuracy score')\n    plt.ylim(0.6, 1)\n    plt.legend(prop={'size': 12}, loc=3)\n    title = \"Min child weight:\" + str(weight)\n    plt.title(title, size=16)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T14:40:25.244448Z","iopub.execute_input":"2023-09-18T14:40:25.244907Z","iopub.status.idle":"2023-09-18T14:54:51.925910Z","shell.execute_reply.started":"2023-09-18T14:40:25.244867Z","shell.execute_reply":"2023-09-18T14:54:51.923465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T14:55:47.587697Z","iopub.execute_input":"2023-09-18T14:55:47.588113Z","iopub.status.idle":"2023-09-18T14:55:47.594604Z","shell.execute_reply.started":"2023-09-18T14:55:47.588082Z","shell.execute_reply":"2023-09-18T14:55:47.593270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Approach 4- Autoencoder representations feeding a decision tree","metadata":{}},{"cell_type":"markdown","source":"This approach trains an autoencoder which is a feed forward network whose input and output layers have the same shape and whose goal is to try and accurately transform the data into a richer representation. \nFirstly, the preprocessing creates two variables x_norm and x_fraud which correspond to the features of records where the transaction is Genuine and Fraudulent.\nNext, the autoencoder is trained on x_norm alone(so it can better distinguish the unseen x_fraud features) and weights of the first 3 layers are added to a new feedforward network which predicts the hidden representation of x_norm and x_train\nthe new representations of x_norm nd x_fraud are fed into a decision tree classifier","metadata":{}},{"cell_type":"code","source":"# this cell contains all our neural network helper functions\ndef preprocessing(data,features):\n    pca = PCA(n_components=8)\n    dat_norm = data[(data[\"Fraudulent Flag\"]== 1)][features]\n    dat_fraud =data[(data[\"Fraudulent Flag\"]== 1)][features]\n    inne = pd.concat([dat_norm,dat_fraud])\n    scaly = StandardScaler()\n    dat= scaly.fit(inne.values)\n    x_norm = scaly.transform(dat_norm)\n    x_fraud = scaly.transform(dat_fraud) \n    x_norm=pca.fit_transform(x_norm)\n    x_fraud=pca.transform(x_fraud)\n    del(inne)\n    return x_norm, x_fraud\n\n\ndef build_net_no_dropout(input_size):\n    model = Sequential()\n    model.add(Dense(input_size,activation = 'relu'))\n    model.add(tf.Flatten())\n    model.add(Dense(64, activation = \"tanh\"))\n    model.add(Dense(128, activation = \"relu\"))\n    model.add(Dense(32, activation = \"tanh\"))\n    model.add(Dense(1, activation = 'sigmoid'))\n    return model\n\ndef build_autoencoder(input_size):\n    model = Sequential()\n    model.add(Dense(input_size,activation = 'tanh'))\n    model.add(Dense(150, activation = \"tanh\"))\n    model.add(Dense(26, activation = \"relu\"))\n    model.add(Dense(150, activation = \"tanh\"))\n    model.add(Dense(150, activation = \"tanh\"))\n    model.add(Dense(input_size, activation = 'relu'))\n    return model\n\ndef build_net_with_dropout(input_size):\n    model = Sequential()\n    model.add(Dense(input_size,activation = 'relu',kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(Dense(128, activation = \"relu\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(tf.keras.layers.Dropout(0.7))\n    model.add(Dense(64, activation = \"tanh\",kernel_regularizer = tf.keras.regularizers.L1(0.01)))\n    model.add(Dense(1, activation = 'sigmoid'))\n    return model\n\ndef model_run(model,train_x,val_y, train_y, val_x, num_epochs):\n    loss = tf.keras.losses.BinaryCrossentropy()\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n    model.compile( loss= loss, optimizer = \"adadelta\", metrics = [\"accuracy\"])\n    #training\n    history = model.fit(train_x,train_y, epochs = num_epochs,batch_size= 70, verbose = 1,validation_data = (val_x,val_y))\n    return history\n\ndef auto_model_run(model,train_x, num_epochs):\n    model.compile( loss= \"mse\", optimizer = \"adadelta\", metrics = [\"accuracy\"])\n    #training\n    history = model.fit(train_x,train_x,epochs = num_epochs,batch_size= 400, verbose = 1,validation_split=0.2)\n    return history\ndef plotter(history,metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric])\n    plt.xlabel('Epochs')\n    plt.ylabel(metric)\n    plt.legend([metric,'val_'+metric])\n    plt.show()\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-18T14:57:13.756679Z","iopub.execute_input":"2023-09-18T14:57:13.757122Z","iopub.status.idle":"2023-09-18T14:57:13.782419Z","shell.execute_reply.started":"2023-09-18T14:57:13.757087Z","shell.execute_reply":"2023-09-18T14:57:13.781117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#autoencoder\nx_norm,x_fraud =preprocessing(data,all_features) \nautoencoder = build_autoencoder(x_norm.shape[1])\nhist_auto = auto_model_run(autoencoder,x_norm,20)\nplotter(hist_auto, \"accuracy\")\nplotter(hist_auto, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:00:28.811001Z","iopub.execute_input":"2023-09-18T15:00:28.811434Z","iopub.status.idle":"2023-09-18T15:12:13.608377Z","shell.execute_reply.started":"2023-09-18T15:00:28.811402Z","shell.execute_reply":"2023-09-18T15:12:13.607158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hidden representation prediction\nhidden_representation =Sequential()\nhidden_representation.add(autoencoder.layers[0])\nhidden_representation.add(autoencoder.layers[1])\nhidden_representation.add(autoencoder.layers[2])","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:12:36.622908Z","iopub.execute_input":"2023-09-18T15:12:36.623325Z","iopub.status.idle":"2023-09-18T15:12:36.634438Z","shell.execute_reply.started":"2023-09-18T15:12:36.623289Z","shell.execute_reply":"2023-09-18T15:12:36.633528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting the hidden representation and feeding it to a classifier\nnorm_hid_rep = hidden_representation.predict(x_norm)\nfraud_hid_rep = hidden_representation.predict(x_fraud)\nrep_x = np.vstack((norm_hid_rep,fraud_hid_rep))\nrep_y = np.hstack((np.zeros(len(x_norm)),np.ones(len(x_fraud))))\nx_train2,x_test2,y_train2,y_test2 = train_test_split(rep_x,rep_y,random_state =22)\n\nclfauto=LogisticRegression(solver =\"lbfgs\").fit(x_train2,y_train2)\ny_predauto = clfauto.predict(x_test2)\nprint(classification_report(y_test2,y_predauto))\n\nfig, ax =plt.subplots()\nsns.heatmap(confusion_matrix(y_test2,y_predauto, normalize='true'), annot =True,ax= ax)\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real value\")\nax.set_xlabel(\"predicted value\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:24:51.711338Z","iopub.execute_input":"2023-09-18T15:24:51.711774Z","iopub.status.idle":"2023-09-18T15:29:53.876338Z","shell.execute_reply.started":"2023-09-18T15:24:51.711734Z","shell.execute_reply":"2023-09-18T15:29:53.874989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently this model fell short of expectations,albeit it seemed to have distinctively recognized the fraudulent and non fraudulent transaction As expected. suspect thant some hyperparameter tunning could help fix the accuracy","metadata":{}},{"cell_type":"markdown","source":" ## Approach 5-  CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nX=data_copy[all_features]\ny=data_copy[\"Fraudulent Flag\"]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n\ncat_features =[all_features.index(w) for w in categorical_features]\ncat = CatBoostClassifier(\n    iterations=26, \n    learning_rate=0.7, \n    loss_function='CrossEntropy'\n)\n\n\ncat.fit(X_train, y_train, \n        cat_features=cat_features, \n        eval_set=(X_val, y_val), \n        verbose=5\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:04.587905Z","iopub.execute_input":"2023-09-18T16:43:04.588498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_val,cat.predict(X_val)))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:41:33.018774Z","iopub.execute_input":"2023-09-18T16:41:33.019273Z","iopub.status.idle":"2023-09-18T16:41:41.478790Z","shell.execute_reply.started":"2023-09-18T16:41:33.019229Z","shell.execute_reply":"2023-09-18T16:41:41.477394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In all it appears that most of our models have similar accuracy and F1 scores, therefore any of them can be used to classify fradulent transactions. That being said there's always room for improvement and with more compute and newer algorithims we will be able to get better**","metadata":{}}]}